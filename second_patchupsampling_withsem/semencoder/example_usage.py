#!/usr/bin/env python3
"""
AutoEncoderä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†å’Œç¼–ç 
"""

import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from pathlib import Path

from model import AutoEncoder
from dataset import DepthImageDataset
from evaluate import ModelEvaluator


def example_1_load_and_inference():
    """ç¤ºä¾‹1: åŠ è½½æ¨¡å‹å¹¶è¿›è¡Œæ¨ç†"""
    print("=" * 60)
    print("ç¤ºä¾‹1: åŠ è½½æ¨¡å‹å¹¶è¿›è¡Œæ¨ç†")
    print("=" * 60)
    
    # æ¨¡å‹è·¯å¾„ - è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…æ¨¡å‹è·¯å¾„
    model_path = "outputs/autoencoder_20250531_225801/best_model_weights.pth"
    
    if not Path(model_path).exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–è€…ä¿®æ”¹æ¨¡å‹è·¯å¾„")
        return
    
    # åˆ›å»ºè¯„ä¼°å™¨
    try:
        evaluator = ModelEvaluator(model_path)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹å›¾åƒï¼ˆéšæœºæ•°æ®ï¼‰
    example_image = torch.randn(1, 1, 128, 128)
    print(f"è¾“å…¥å›¾åƒå½¢çŠ¶: {example_image.shape}")
    
    # ç¼–ç åˆ°æ½œåœ¨ç©ºé—´
    latent_vector = evaluator.encode_image(example_image)
    print(f"æ½œåœ¨å‘é‡å½¢çŠ¶: {latent_vector.shape}")
    print(f"æ½œåœ¨å‘é‡ç»Ÿè®¡: mean={latent_vector.mean():.4f}, std={latent_vector.std():.4f}")
    
    # ä»æ½œåœ¨å‘é‡é‡å»ºå›¾åƒ
    reconstructed = evaluator.decode_latent(latent_vector)
    print(f"é‡å»ºå›¾åƒå½¢çŠ¶: {reconstructed.shape}")
    
    # è®¡ç®—é‡å»ºè¯¯å·®
    mse_error = torch.nn.functional.mse_loss(reconstructed, example_image)
    print(f"é‡å»ºMSEè¯¯å·®: {mse_error.item():.6f}")
    
    print("âœ… æ¨ç†æµ‹è¯•å®Œæˆ")


def example_2_process_real_image():
    """ç¤ºä¾‹2: å¤„ç†çœŸå®æ·±åº¦å›¾åƒ"""
    print("=" * 60)
    print("ç¤ºä¾‹2: å¤„ç†çœŸå®æ·±åº¦å›¾åƒ")
    print("=" * 60)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è™šæ‹Ÿæ•°æ®
    data_dir = "dummy_data"
    if not Path(data_dir).exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("è¯·å…ˆè¿è¡Œ python quick_start.py --create_dummy æ¥åˆ›å»ºæµ‹è¯•æ•°æ®")
        return
    
    # æ¨¡å‹è·¯å¾„
    model_path = "outputs/autoencoder_20250531_225801/best_model_weights.pth"
    if not Path(model_path).exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    try:
        # åŠ è½½æ¨¡å‹
        evaluator = ModelEvaluator(model_path)
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = DepthImageDataset(data_dir, augment=False)
        
        if len(dataset) == 0:
            print("âŒ æ•°æ®é›†ä¸ºç©º")
            return
        
        # è·å–ç¬¬ä¸€å¼ å›¾åƒ
        image = dataset[0]
        print(f"å¤„ç†å›¾åƒå½¢çŠ¶: {image.shape}")
        
        # ç¼–ç å’Œé‡å»º
        reconstructed, latent = evaluator.reconstruct_image(image)
        
        print(f"æ½œåœ¨å‘é‡ç»´åº¦: {latent.shape[1]}")
        print(f"é‡å»ºè¯¯å·®: {torch.nn.functional.mse_loss(reconstructed, image.unsqueeze(0)).item():.6f}")
        
        # å¯è§†åŒ–ç»“æœ
        fig, axes = plt.subplots(1, 3, figsize=(12, 4))
        
        # åŸå›¾
        axes[0].imshow(image[0].numpy(), cmap='viridis', vmin=-1, vmax=1)
        axes[0].set_title('Original')
        axes[0].axis('off')
        
        # é‡å»ºå›¾
        axes[1].imshow(reconstructed[0, 0].numpy(), cmap='viridis', vmin=-1, vmax=1)
        axes[1].set_title('Reconstructed')
        axes[1].axis('off')
        
        # å·®å¼‚å›¾
        diff = torch.abs(image[0] - reconstructed[0, 0]).numpy()
        axes[2].imshow(diff, cmap='hot', vmin=0, vmax=0.5)
        axes[2].set_title('Difference')
        axes[2].axis('off')
        
        plt.tight_layout()
        plt.savefig('example_reconstruction.png', dpi=150, bbox_inches='tight')
        plt.show()
        
        print("âœ… å›¾åƒå¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜ä¸º 'example_reconstruction.png'")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")


def example_3_batch_encoding():
    """ç¤ºä¾‹3: æ‰¹é‡ç¼–ç å›¾åƒ"""
    print("=" * 60)
    print("ç¤ºä¾‹3: æ‰¹é‡ç¼–ç å›¾åƒ")
    print("=" * 60)
    
    data_dir = "dummy_data"
    model_path = "outputs/autoencoder_20250531_225801/best_model_weights.pth"
    
    if not Path(data_dir).exists() or not Path(model_path).exists():
        print("âŒ ç¼ºå°‘æ•°æ®æˆ–æ¨¡å‹æ–‡ä»¶")
        return
    
    try:
        # åŠ è½½æ¨¡å‹
        evaluator = ModelEvaluator(model_path)
        
        # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
        from dataset import create_dataloader
        dataloader = create_dataloader(
            data_dir=data_dir,
            batch_size=4,
            shuffle=False,
            num_workers=0,
            augment=False
        )
        
        print(f"æ•°æ®é›†å¤§å°: {len(dataloader.dataset)}")
        
        # æ‰¹é‡ç¼–ç 
        all_latents = []
        all_images = []
        
        for batch in dataloader:
            with torch.no_grad():
                latents = evaluator.model.encode(batch.to(evaluator.device))
                all_latents.append(latents.cpu())
                all_images.append(batch)
        
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        all_latents = torch.cat(all_latents, dim=0)
        all_images = torch.cat(all_images, dim=0)
        
        print(f"ç¼–ç å®Œæˆ: {all_latents.shape[0]} å¼ å›¾åƒ")
        print(f"æ½œåœ¨å‘é‡å½¢çŠ¶: {all_latents.shape}")
        
        # åˆ†ææ½œåœ¨å‘é‡
        print(f"æ½œåœ¨ç©ºé—´ç»Ÿè®¡:")
        print(f"  å¹³å‡å€¼: {all_latents.mean():.4f}")
        print(f"  æ ‡å‡†å·®: {all_latents.std():.4f}")
        print(f"  æœ€å°å€¼: {all_latents.min():.4f}")
        print(f"  æœ€å¤§å€¼: {all_latents.max():.4f}")
        
        # è®¡ç®—å›¾åƒé—´çš„æ½œåœ¨ç©ºé—´è·ç¦»
        if len(all_latents) >= 2:
            dist = torch.norm(all_latents[0] - all_latents[1])
            print(f"å‰ä¸¤å¼ å›¾åƒçš„æ½œåœ¨ç©ºé—´è·ç¦»: {dist.item():.4f}")
        
        print("âœ… æ‰¹é‡ç¼–ç å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡ç¼–ç å¤±è´¥: {e}")


def example_4_custom_model_usage():
    """ç¤ºä¾‹4: ç›´æ¥ä½¿ç”¨æ¨¡å‹ç±»"""
    print("=" * 60)
    print("ç¤ºä¾‹4: ç›´æ¥ä½¿ç”¨æ¨¡å‹ç±»")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ¨¡å‹
        model = AutoEncoder(input_channels=1, latent_dim=768, output_size=128)
        
        # åŠ è½½æƒé‡
        model_path = "outputs/autoencoder_20250531_225801/best_model_weights.pth"
        if Path(model_path).exists():
            state_dict = torch.load(model_path, map_location='cpu')
            model.load_state_dict(state_dict)
            print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
        else:
            print("âš ï¸ æ¨¡å‹æƒé‡ä¸å­˜åœ¨ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æƒé‡")
        
        model.eval()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = torch.randn(3, 1, 128, 128)
        
        with torch.no_grad():
            # å®Œæ•´çš„å‰å‘ä¼ æ’­
            reconstructed, latent = model(test_data)
            print(f"å®Œæ•´å‰å‘ä¼ æ’­: {test_data.shape} -> {latent.shape} -> {reconstructed.shape}")
            
            # åªç¼–ç 
            encoded = model.encode(test_data)
            print(f"ä»…ç¼–ç : {test_data.shape} -> {encoded.shape}")
            
            # åªè§£ç 
            decoded = model.decode(encoded)
            print(f"ä»…è§£ç : {encoded.shape} -> {decoded.shape}")
            
            # éªŒè¯ä¸€è‡´æ€§
            diff = torch.mean(torch.abs(reconstructed - decoded))
            print(f"ç¼–ç -è§£ç ä¸€è‡´æ€§è¯¯å·®: {diff.item():.6f}")
        
        print("âœ… ç›´æ¥æ¨¡å‹ä½¿ç”¨æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ ç›´æ¥æ¨¡å‹ä½¿ç”¨å¤±è´¥: {e}")


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ AutoEncoder ä½¿ç”¨ç¤ºä¾‹")
    print("è¿™äº›ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„AutoEncoderæ¨¡å‹")
    
    # è¿è¡Œç¤ºä¾‹
    example_1_load_and_inference()
    example_2_process_real_image()
    example_3_batch_encoding()
    example_4_custom_model_usage()
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ ä½¿ç”¨å°ç»“:")
    print("1. ä½¿ç”¨ ModelEvaluator ç±»æœ€æ–¹ä¾¿")
    print("2. æ”¯æŒå•å¼ å›¾åƒå’Œæ‰¹é‡å¤„ç†")
    print("3. æ½œåœ¨å‘é‡å¯ç”¨äºä¸‹æ¸¸ä»»åŠ¡")
    print("4. å¯ä»¥è¿›è¡Œå›¾åƒé‡å»ºå’Œè´¨é‡è¯„ä¼°")
    print("=" * 60)


if __name__ == '__main__':
    main() 