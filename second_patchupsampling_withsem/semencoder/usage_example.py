#!/usr/bin/env python3
"""
è¯­ä¹‰ç¼–ç å™¨ä½¿ç”¨ç¤ºä¾‹

æœ¬æ–‡ä»¶æ¼”ç¤ºäº†å¦‚ä½•ï¼š
1. ä»è®­ç»ƒå¥½çš„AutoEncoderä¸­æå–Encoderæƒé‡
2. åœ¨å…¶ä»–é¡¹ç›®ä¸­ä½¿ç”¨SemanticEncoder
3. å„ç§ä½¿ç”¨åœºæ™¯å’Œå‚æ•°æ§åˆ¶
"""

import torch
import numpy as np
from pathlib import Path

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from extract_encoder import extract_encoder_weights
from semantic_encoder import SemanticEncoder, create_semantic_encoder


def example_1_extract_encoder_weights():
    """ç¤ºä¾‹1: ä»AutoEncoderæ£€æŸ¥ç‚¹æå–Encoderæƒé‡"""
    print("=" * 60)
    print("ç¤ºä¾‹1: æå–Encoderæƒé‡")
    print("=" * 60)
    
    # å‡è®¾ä½ æœ‰ä¸€ä¸ªè®­ç»ƒå¥½çš„AutoEncoderæ£€æŸ¥ç‚¹
    autoencoder_checkpoint = "outputs/autoencoder_20250601_134120/best_model.pth"
    
    try:
        # æå–encoderæƒé‡
        encoder_weights_path = extract_encoder_weights(
            autoencoder_checkpoint_path=autoencoder_checkpoint,
            output_path="encoder_weights.pth",  # å¯é€‰ï¼Œä¸æŒ‡å®šä¼šè‡ªåŠ¨ç”Ÿæˆ
            input_channels=1,
            latent_dim=768
        )
        print(f"âœ“ Encoderæƒé‡å·²æå–åˆ°: {encoder_weights_path}")
        return encoder_weights_path
        
    except FileNotFoundError:
        print("âš ï¸  æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ­¤ç¤ºä¾‹")
        print("   è¯·ç¡®ä¿æœ‰æœ‰æ•ˆçš„AutoEncoderæ£€æŸ¥ç‚¹æ–‡ä»¶")
        return None
    except Exception as e:
        print(f"âŒ æå–å¤±è´¥: {e}")
        return None


def example_2_basic_usage(encoder_weights_path: str = None):
    """ç¤ºä¾‹2: åŸºæœ¬ä½¿ç”¨æ–¹æ³•"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹2: åŸºæœ¬ä½¿ç”¨æ–¹æ³•")
    print("=" * 60)
    
    # æ–¹æ³•1: ç›´æ¥åˆ›å»ºï¼ˆä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼‰
    print("\n--- æ–¹æ³•1: åˆ›å»ºéšæœºåˆå§‹åŒ–çš„encoder ---")
    encoder = SemanticEncoder(
        input_channels=1,
        latent_dim=768,
        freeze_weights=False
    )
    
    # æ–¹æ³•2: åˆ›å»ºå¹¶åŠ è½½é¢„è®­ç»ƒæƒé‡
    if encoder_weights_path and Path(encoder_weights_path).exists():
        print("\n--- æ–¹æ³•2: åŠ è½½é¢„è®­ç»ƒæƒé‡ ---")
        encoder_pretrained = SemanticEncoder(
            input_channels=1,
            latent_dim=768,
            pretrained_path=encoder_weights_path,
            freeze_weights=False
        )
    else:
        print("\n--- æ–¹æ³•2: è·³è¿‡ï¼ˆæ— é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ï¼‰ ---")
        encoder_pretrained = encoder
    
    # æ–¹æ³•3: ä½¿ç”¨ä¾¿æ·å‡½æ•°
    print("\n--- æ–¹æ³•3: ä½¿ç”¨ä¾¿æ·å‡½æ•° ---")
    if encoder_weights_path and Path(encoder_weights_path).exists():
        encoder_easy = create_semantic_encoder(
            pretrained_path=encoder_weights_path,
            freeze_weights=True  # å†»ç»“æƒé‡ç”¨äºç‰¹å¾æå–
        )
    else:
        print("è·³è¿‡ä¾¿æ·å‡½æ•°ç¤ºä¾‹ï¼ˆæ— é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ï¼‰")
        encoder_easy = encoder
    
    return encoder_pretrained


def example_3_inference(encoder: SemanticEncoder):
    """ç¤ºä¾‹3: æ¨ç†ä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹3: æ¨ç†ä½¿ç”¨")
    print("=" * 60)
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    batch_size = 4
    height, width = 128, 128
    
    # æ–¹æ³•1: PyTorch tensorè¾“å…¥
    print("\n--- æ–¹æ³•1: PyTorch Tensoræ¨ç† ---")
    tensor_input = torch.randn(batch_size, 1, height, width)
    
    with torch.no_grad():
        embeddings = encoder.encode(tensor_input)
    
    print(f"è¾“å…¥å½¢çŠ¶: {tensor_input.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {embeddings.shape}")
    print(f"è¾“å‡ºæ•°æ®ç±»å‹: {embeddings.dtype}")
    
    # æ–¹æ³•2: NumPyæ•°ç»„è¾“å…¥
    print("\n--- æ–¹æ³•2: NumPyæ•°ç»„æ¨ç† ---")
    numpy_input = np.random.randn(batch_size, height, width)  # [N, H, W]
    
    embeddings_numpy = encoder.encode_numpy(
        numpy_input, 
        batch_size=2,  # åˆ†æ‰¹å¤„ç†
        normalize=True  # è‡ªåŠ¨å½’ä¸€åŒ–
    )
    
    print(f"NumPyè¾“å…¥å½¢çŠ¶: {numpy_input.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {embeddings_numpy.shape}")
    print(f"è¾“å‡ºæ•°æ®ç±»å‹: {embeddings_numpy.dtype}")
    
    # æ–¹æ³•3: å¤§æ‰¹é‡æ¨ç†
    print("\n--- æ–¹æ³•3: å¤§æ‰¹é‡æ¨ç† ---")
    large_batch = torch.randn(100, 1, height, width)
    
    large_embeddings = encoder.encode_batch(
        large_batch,
        batch_size=16  # åˆ†æ‰¹å¤„ç†é¿å…å†…å­˜æº¢å‡º
    )
    
    print(f"å¤§æ‰¹é‡è¾“å…¥å½¢çŠ¶: {large_batch.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {large_embeddings.shape}")


def example_4_parameter_control(encoder: SemanticEncoder):
    """ç¤ºä¾‹4: å‚æ•°æ§åˆ¶ï¼ˆå†»ç»“/è§£å†»ï¼‰"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹4: å‚æ•°æ§åˆ¶")
    print("=" * 60)
    
    # æŸ¥çœ‹åˆå§‹çŠ¶æ€
    print("--- åˆå§‹çŠ¶æ€ ---")
    info = encoder.get_model_info()
    print(f"æ€»å‚æ•°: {info['total_parameters']:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {info['trainable_parameters']:,}")
    
    # å†»ç»“æ‰€æœ‰å‚æ•°
    print("\n--- å†»ç»“æ‰€æœ‰å‚æ•° ---")
    encoder.freeze_parameters(True)
    print(f"å†»ç»“åå¯è®­ç»ƒå‚æ•°: {encoder.count_parameters(only_trainable=True):,}")
    
    # è§£å†»æ‰€æœ‰å‚æ•°
    print("\n--- è§£å†»æ‰€æœ‰å‚æ•° ---")
    encoder.freeze_parameters(False)
    print(f"è§£å†»åå¯è®­ç»ƒå‚æ•°: {encoder.count_parameters(only_trainable=True):,}")
    
    # å†»ç»“ç‰¹å®šå±‚
    print("\n--- å†»ç»“ç‰¹å®šå±‚ ---")
    encoder.freeze_layers(['stem', 'layer1', 'layer2'])
    print(f"éƒ¨åˆ†å†»ç»“åå¯è®­ç»ƒå‚æ•°: {encoder.count_parameters(only_trainable=True):,}")
    
    # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    print(f"\n--- æ¨¡å‹è¯¦ç»†ä¿¡æ¯ ---")
    print(encoder)


def example_5_practical_usage():
    """ç¤ºä¾‹5: å®é™…åº”ç”¨åœºæ™¯"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹5: å®é™…åº”ç”¨åœºæ™¯")
    print("=" * 60)
    
    # åœºæ™¯1: ä½œä¸ºé¢„è®­ç»ƒç‰¹å¾æå–å™¨
    print("\n--- åœºæ™¯1: é¢„è®­ç»ƒç‰¹å¾æå–å™¨ ---")
    feature_extractor = SemanticEncoder(
        input_channels=1,
        latent_dim=768,
        freeze_weights=True  # å†»ç»“æƒé‡ï¼Œåªç”¨äºç‰¹å¾æå–
    )
    
    # å¤„ç†ä¸€æ‰¹å›¾åƒæ•°æ®
    images = torch.randn(10, 1, 128, 128)
    features = feature_extractor.encode_batch(images, batch_size=5)
    print(f"æå–äº† {features.shape[0]} ä¸ªæ ·æœ¬çš„ç‰¹å¾ï¼Œæ¯ä¸ªç‰¹å¾ç»´åº¦: {features.shape[1]}")
    
    # åœºæ™¯2: ä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„backbone
    print("\n--- åœºæ™¯2: ä¸‹æ¸¸ä»»åŠ¡backbone ---")
    class DownstreamModel(torch.nn.Module):
        def __init__(self, encoder_path: str = None):
            super().__init__()
            
            # åŠ è½½é¢„è®­ç»ƒçš„encoder
            self.backbone = SemanticEncoder(
                input_channels=1,
                latent_dim=768,
                pretrained_path=encoder_path,
                freeze_weights=False  # å…è®¸å¾®è°ƒ
            )
            
            # å†»ç»“æ—©æœŸå±‚ï¼Œåªå¾®è°ƒåé¢çš„å±‚
            self.backbone.freeze_layers(['stem', 'layer1'])
            
            # æ·»åŠ ä»»åŠ¡ç‰¹å®šçš„å¤´éƒ¨
            self.classifier = torch.nn.Sequential(
                torch.nn.Linear(768, 256),
                torch.nn.ReLU(),
                torch.nn.Dropout(0.1),
                torch.nn.Linear(256, 10)  # å‡è®¾10ä¸ªç±»åˆ«
            )
        
        def forward(self, x):
            features = self.backbone.encode(x)
            return self.classifier(features)
    
    # åˆ›å»ºä¸‹æ¸¸æ¨¡å‹
    downstream_model = DownstreamModel()
    
    # æµ‹è¯•
    test_input = torch.randn(3, 1, 128, 128)
    output = downstream_model(test_input)
    print(f"ä¸‹æ¸¸ä»»åŠ¡è¾“å‡ºå½¢çŠ¶: {output.shape}")
    
    # åœºæ™¯3: ç›¸ä¼¼åº¦è®¡ç®—
    print("\n--- åœºæ™¯3: ç›¸ä¼¼åº¦è®¡ç®— ---")
    encoder = SemanticEncoder(input_channels=1, latent_dim=768)
    
    # è®¡ç®—ä¸¤ä¸ªå›¾åƒçš„ç›¸ä¼¼åº¦
    img1 = torch.randn(1, 1, 128, 128)
    img2 = torch.randn(1, 1, 128, 128)
    
    with torch.no_grad():
        feat1 = encoder.encode(img1)
        feat2 = encoder.encode(img2)
        
        # ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = torch.nn.functional.cosine_similarity(feat1, feat2)
        print(f"å›¾åƒç›¸ä¼¼åº¦: {similarity.item():.4f}")


def example_6_model_saving_loading():
    """ç¤ºä¾‹6: æ¨¡å‹ä¿å­˜å’ŒåŠ è½½"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹6: æ¨¡å‹ä¿å­˜å’ŒåŠ è½½")
    print("=" * 60)
    
    # åˆ›å»ºä¸€ä¸ªencoder
    encoder = SemanticEncoder(input_channels=1, latent_dim=768)
    
    # ä¿å­˜æƒé‡
    save_path = "my_encoder_weights.pth"
    encoder.save_encoder_weights(save_path)
    
    # åˆ›å»ºæ–°çš„encoderå¹¶åŠ è½½æƒé‡
    new_encoder = SemanticEncoder(
        input_channels=1,
        latent_dim=768,
        pretrained_path=save_path
    )
    
    # éªŒè¯åŠ è½½æ˜¯å¦æˆåŠŸ
    test_input = torch.randn(1, 1, 128, 128)
    with torch.no_grad():
        output1 = encoder.encode(test_input)
        output2 = new_encoder.encode(test_input)
        
        # æ£€æŸ¥è¾“å‡ºæ˜¯å¦ç›¸åŒ
        diff = torch.abs(output1 - output2).max()
        print(f"åŠ è½½å‰åè¾“å‡ºå·®å¼‚: {diff.item():.8f}")
        
        if diff < 1e-6:
            print("âœ“ æƒé‡åŠ è½½æˆåŠŸï¼")
        else:
            print("âŒ æƒé‡åŠ è½½å¯èƒ½æœ‰é—®é¢˜")


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ è¯­ä¹‰ç¼–ç å™¨ä½¿ç”¨ç¤ºä¾‹")
    print("æœ¬ç¤ºä¾‹å°†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨è¯­ä¹‰ç¼–ç å™¨çš„å„ç§åŠŸèƒ½")
    
    # ç¤ºä¾‹1: æå–encoderæƒé‡
    encoder_weights_path = example_1_extract_encoder_weights()
    
    # ç¤ºä¾‹2: åŸºæœ¬ä½¿ç”¨
    encoder = example_2_basic_usage(encoder_weights_path)
    
    # ç¤ºä¾‹3: æ¨ç†ä½¿ç”¨
    example_3_inference(encoder)
    
    # ç¤ºä¾‹4: å‚æ•°æ§åˆ¶
    example_4_parameter_control(encoder)
    
    # ç¤ºä¾‹5: å®é™…åº”ç”¨åœºæ™¯
    example_5_practical_usage()
    
    # ç¤ºä¾‹6: ä¿å­˜å’ŒåŠ è½½
    example_6_model_saving_loading()
    
    print("\n" + "=" * 60)
    print("âœ“ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main() 